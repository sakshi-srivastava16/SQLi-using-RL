import pandas as pd
from joblib import load
import numpy as np
from agent import DQNAgent
from mockSQLenv import SQLInjectionEnv
from agent import Agent


def main():
    # Load the trained SQLi detection model
    model = load("sqli_model.pkl")

    # Load your dataset for the environment
    dataset = pd.read_csv("sqli_dataset.csv")
    queries = dataset["query"].tolist()

    # Initialize SQL Injection Environment
    env = SQLInjectionEnv(model, queries)

    # Define parameters for DQNAgent
    action_space = len(env.actions)
    state_size = env.state_size

    actions = env.actions

    # Initialize DQNAgent
    agent = DQNAgent(action_space=action_space, state_size=state_size)
    simpleAgent = Agent(actions=actions)

    # Training parameters
    episodes = 15  # Number of training episodes
    max_steps = 50  # Maximum steps per episode to prevent infinite loops

    # lists for each agent's generated queries
    generated_queries_dqnAgent = []  # To store the queries generated by the DQN agent
    generated_queries_simpleAgent = (
        []
    )  # To store the queries generated by the simpleAgent

    # Initialize Q-table for simpleAgent
    simpleAgent.initialize_q_table(len(queries))

    # Training loop for DQNAgent
    for episode in range(episodes):
        # Reset environment and get the initial state
        state = env.reset()

        done = False
        total_reward = 0
        step = 0  # Step counter for the episode

        while not done and step < max_steps:
            # Select an action using the DQN agent
            action = agent.select_action(state)

            # Modify the query based on the selected action
            modified_query = env.modify_query(env.queries[state.argmax()], action)

            # Store the generated query for DQN agent
            generated_queries_dqnAgent.append(modified_query)

            # Apply the selected action in the environment
            next_state, reward, done, debug_msg = env.step(action)

            # # Print debugging info for each step
            # print(debug_msg)

            # Store experience in replay buffer
            agent.store_experience(state, action, reward, next_state, done)

            # Train the agent after storing experience
            agent.train(batch_size=32)

            # Update state and total reward
            state = next_state
            total_reward += reward
            step += 1  # Increment step counter

        print(
            f"Episode {episode + 1}/{episodes}, Reward: {total_reward}, Steps: {step}"
        )

        # Update target network periodically (e.g., every 10 episodes)
        if episode % 10 == 0:
            agent.update_target_network()

    print("Training complete for DQNAgent.")

    # Training loop for simpleAgent
    for episode in range(episodes):
        # Reset environment and get the initial state
        state = env.reset()

        done = False
        total_reward = 0
        step = 0  # Step counter for the episode

        while not done and step < max_steps:
            # Select an action using the simpleAgent
            state_index = np.argmax(state)  # Get the index of the current state
            action = simpleAgent.select_action(state_index)

            # Modify the query based on the selected action
            modified_query = env.modify_query(env.queries[state_index], action)

            # Store the generated query for simpleAgent
            generated_queries_simpleAgent.append(modified_query)

            # Apply the selected action in the environment
            next_state, reward, done, debug_msg = env.step(action)

            # Print debugging info for each step
            # print(debug_msg)

            # Update the Q-table based on experience
            simpleAgent.update_q_table(
                state_index, action, reward, np.argmax(next_state)
            )

            # Decay epsilon for exploration-exploitation trade-off
            simpleAgent.decay_epsilon()

            # Update state and total reward
            state = next_state
            total_reward += reward
            step += 1  # Increment step counter

        print(
            f"Episode {episode + 1}/{episodes}, Reward: {total_reward}, Steps: {step}"
        )

    print("Training complete for simpleAgent.")

    # Generate CSV file with the queries generated by the DQN agent
    generated_queries_dqnAgent_df = pd.DataFrame(
        generated_queries_dqnAgent, columns=["Generated Queries"]
    )
    generated_queries_dqnAgent_df.to_csv(
        "generated_queries_Agent1_dqn.csv", index=False
    )
    print(
        "Generated queries for DQN agent have been saved to 'generated_queries_dqnAgent.csv'."
    )

    # Generate CSV file with the queries generated by the simpleAgent
    generated_queries_simpleAgent_df = pd.DataFrame(
        generated_queries_simpleAgent, columns=["Generated Queries"]
    )
    generated_queries_simpleAgent_df.to_csv(
        "generated_queries_Agent2_simple.csv", index=False
    )
    print(
        "Generated queries for simpleAgent have been saved to 'generated_queries_simpleAgent.csv'."
    )

    # Accepting user input for detection
    user_query = input("Enter a SQL query to detect if it's malicious: ")
    env.set_query(user_query)  # Assuming `set_query` is defined in SQLInjectionEnv

    # Use environment's check_bypass to detect malicious intent
    result = env.check_bypass(user_query)
    if result:
        print("The query is detected as malicious.")
    else:
        print("The query is detected as benign (bypass was successful).")


if __name__ == "__main__":
    main()
